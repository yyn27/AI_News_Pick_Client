# âœ… ìˆ˜ì •ëœ core/main_scripts_blog_ui_api.py

import os
import re
import pandas as pd
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed
from core.core_utils_ui_api import (
    clean_text, extract_first_sentences, generate_search_queries,
    search_naver_news_api, calculate_copy_ratio, log
)

import sys
def resource_path(relative_path):
    """å…¼å®¹PyInstallerå’Œæºç è¿è¡Œçš„èµ„æºè·¯å¾„"""
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, relative_path)
    return os.path.join(os.path.abspath("."), relative_path)

def find_original_article_api(index, row_dict, total_count, output_dir, stop_event_flag, client_id, client_secret):
    try:
        # æ£€æŸ¥ä¸­æ–­
        if stop_event_flag:
            log("ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ ê°ì§€, ì‘ì—… ì¤‘ë‹¨", index)
            return index, "", 0.0
        
        title = clean_text(str(row_dict.get("ê²Œì‹œê¸€ì œëª©", "")))
        content = clean_text(str(row_dict.get("ê²Œì‹œê¸€ë‚´ìš©", "")))
        press = clean_text(str(row_dict.get("ê²€ìƒ‰ì–´", "")))
        first, second, last = extract_first_sentences(content)
        queries = generate_search_queries(title, first, second, last, press)
        log(f"ğŸ” ê²€ìƒ‰ì–´: {queries}", index)

        # æ£€æŸ¥ä¸­æ–­
        if stop_event_flag:
            log("ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ ê°ì§€, ì‘ì—… ì¤‘ë‹¨", index)
            return index, "", 0.0

        search_results = search_naver_news_api(queries, index, client_id, client_secret)
        if not search_results:
            log("âŒ ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ", index)
            return index, "", 0.0
        
        # æ£€æŸ¥ä¸­æ–­
        if stop_event_flag:
            log("ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ ê°ì§€, ì‘ì—… ì¤‘ë‹¨", index)
            return index, "", 0.0

        best = max(search_results, key=lambda x: calculate_copy_ratio(x["body"], title + " " + content))
        score = calculate_copy_ratio(best["body"], title + " " + content)

        if score >= 0.0:
            safe_title = re.sub(r'[\\/*?:"<>|]', '', title)[:50]
            filename = os.path.join(output_dir, f"{index+1:03d}_{safe_title}.txt")
            with open(filename, "w", encoding="utf-8") as f:
                f.write(f"[URL] {best['link']}\n\n{best['body']}")
            log(f"ğŸ“ ì €ì¥ ì™„ë£Œ â†’ {filename} (ë³µì‚¬ìœ¨: {score})", index)
            hyperlink = f'=HYPERLINK("{best["link"]}")'
            return index, hyperlink, score
        else:
            log(f"âš ï¸ ë³µì‚¬ìœ¨ ë‚®ìŒ (ë³µì‚¬ìœ¨: {score})", index)
            return index, "", 0.0

    except Exception as e:
        log(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}", index)
        return index, "", 0.0

def main(input_path, output_path, client_id, client_secret, stop_event=None):
    output_dir = os.path.splitext(output_path)[0] + "_ë³¸ë¬¸"
    os.makedirs(output_dir, exist_ok=True)

    df = pd.read_excel(input_path, dtype={"ê²Œì‹œê¸€ ë“±ë¡ì¼ì": str})
    total = len(df)
    log(f"ğŸ“„ ì „ì²´ ê²Œì‹œê¸€ ìˆ˜: {total}ê°œ")

    df["ì›ë³¸ê¸°ì‚¬"] = ""
    df["ë³µì‚¬ìœ¨"] = 0.0

    def get_stop_flag():
        return stop_event.is_set() if stop_event else False

    tasks = [(i, row.to_dict(), total, output_dir, get_stop_flag(), client_id, client_secret) for i, row in df.iterrows()]

    with ProcessPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(find_original_article_api, *args) for args in tasks]
        try:
            for future in as_completed(futures):
                if stop_event and stop_event.is_set():
                    log("ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ ê°ì§€, ì‘ì—… ì¤‘ë‹¨")
                    executor.shutdown(cancel_futures=True)
                    break
                try:
                    index, link, score = future.result()
                    df.at[index, "ì›ë³¸ê¸°ì‚¬"] = link
                    df.at[index, "ë³µì‚¬ìœ¨"] = score
                except Exception as e:
                    log(f"âŒ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        except Exception as e:
            log(f"âŒ í”„ë¡œì„¸ìŠ¤ í’€ ì—ëŸ¬: {e}")

    matched_count = df["ë³µì‚¬ìœ¨"].gt(0).sum()
    above_90_count = df["ë³µì‚¬ìœ¨"].ge(0.9).sum()
    above_50_count = df["ë³µì‚¬ìœ¨"].ge(0.5).sum() - above_90_count
    above_0_count = matched_count - above_90_count - above_50_count

    stats_rows = pd.DataFrame([
        {"ìˆœë²ˆ": "ë§¤ì¹­ê±´ìˆ˜", "ê²€ìƒ‰": f"{matched_count}ê±´"},
        {"ìˆœë²ˆ": "0.5 ì´ìƒ", "ê²€ìƒ‰": f"{above_50_count}ê±´"},
        {"ìˆœë²ˆ": "0.9 ì´ìƒ", "ê²€ìƒ‰": f"{above_90_count}ê±´"},
        {"ìˆœë²ˆ": "0 ì´ìƒ", "ê²€ìƒ‰": f"{above_0_count}ê±´"},
    ])
    df = pd.concat([df, stats_rows], ignore_index=True)
    df.to_excel(output_path, index=False)

    log("ğŸ“Š í†µê³„ ìš”ì•½")
    log(f" ë§¤ì¹­ê±´ìˆ˜: {matched_count}ê±´")
    log(f" 0.5 ì´ìƒ: {above_50_count}ê±´")
    log(f" 0.9 ì´ìƒ: {above_90_count}ê±´")
    log(f" 0 ì´ìƒ: {above_0_count}ê±´")
    log(f"ğŸ‰ ì™„ë£Œ! ì €ì¥ë¨ â†’ {output_path}")

# ä¸è¦è‡ªåŠ¨è¿è¡Œ main()ï¼Œç”±å…¥å£æ–‡ä»¶è°ƒç”¨